11/8/2022 Notes

Modified analysis.py to make plots for many stats vs cycles in sequence
Used Latitude7480, Latitude7480 test from 11/6 for the below:

gcc -O1 w/ pf on seems to have a few outliers for several statistics
e.g., context-switches, L1-dcache-load-misses, cpu-migrations, branch-misses, iTLB-load-misses

One possible explanation is that this is the FIRST -O(>0) optimization level
we run, so the cache, etc. might not be tuned to the particular optimized
memory layout during the first couple runs
However, afterwards all of the optimization levels yield a similar memory
structure, so the higher levels don't show this behavior as the cache, etc.
are already set up for that approx memory layout

L1-dcache-loads seems to only depend on optimization level
same with page-faults, which is EXTREMELY consistent --> large for -O0, smaller for -O1+
instructions also doesn't depend on anything but optimization being -O0 or -O1+
also same with dTLB-loads

L1-dcache-load-misses has large variance within 
cpu-migrations also has reasonable variation, from 0-4 in general
	-> A whole bunch (8-14) for -O1 pf on sometimes

branch-misses is mostly unaffected by prefetch and compiler flags
However, -O1 has a large number of misses for a few outliers

branches are pretty variable within optimization levels, but unaffected by prefetch

dTLB-load-misses increases in general with the prefetcher on for -O0
Largely unaffected for other optimization levels
Could be that the hardware prefetcher can't go across page lines, but we need to?
Or that there are more loads total to miss on (though we didn't see this)

iTLB-loads looks approximately linear in number of cycles
Fewer with prefetcher on
NO -O1 outlier here

iTLB-load-misses are a bit more for -O0 than -O1+, except for one outlier in -O1
-Ofast here bunches the number of misses narrowly, but is generally higher than -O1/-O2
MAY want to exclude the outlier and re-plot this!!!

TO TEST: What happens if we reorder the optimization levels?
	What happens if we include some blank executions to warm up the processor?
	(that is, we don't measure with perf for a couple runs in between)

Questions: Why are branches variable between fixed optimization levels and prefetcher status?
	Shouldn't the program, and its branch behavior, be deterministic?
	Do the trace cache and/or loop unrolling contribute?



